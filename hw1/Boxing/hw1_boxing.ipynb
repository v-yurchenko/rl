{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ROa9tyTLOaYI",
    "outputId": "d7ccc693-d195-45df-93f3-b905b85be76e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "Collecting gym[accept-rom-license,atari,classic-control]==0.25.2\n",
      "  Downloading gym-0.25.2.tar.gz (734 kB)\n",
      "     |████████████████████████████████| 734 kB 1.2 MB/s            \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[33mWARNING: gym 0.25.2 does not provide the extra 'classic-control'\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /home/user/conda/lib/python3.7/site-packages (from gym[accept-rom-license,atari,classic-control]==0.25.2) (1.21.5)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/jovyan/.imgenv-vlad-rl-0/lib/python3.7/site-packages (from gym[accept-rom-license,atari,classic-control]==0.25.2) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /home/user/conda/lib/python3.7/site-packages (from gym[accept-rom-license,atari,classic-control]==0.25.2) (4.10.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/user/conda/lib/python3.7/site-packages (from gym[accept-rom-license,atari,classic-control]==0.25.2) (2.0.0)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /home/jovyan/.imgenv-vlad-rl-0/lib/python3.7/site-packages (from gym[accept-rom-license,atari,classic-control]==0.25.2) (0.4.2)\n",
      "Collecting ale-py~=0.7.5\n",
      "  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "     |████████████████████████████████| 1.6 MB 10.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: importlib-resources in /home/user/conda/lib/python3.7/site-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari,classic-control]==0.25.2) (5.4.0)\n",
      "Requirement already satisfied: requests in /home/user/conda/lib/python3.7/site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari,classic-control]==0.25.2) (2.27.1)\n",
      "Requirement already satisfied: click in /home/user/conda/lib/python3.7/site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari,classic-control]==0.25.2) (8.0.3)\n",
      "Requirement already satisfied: tqdm in /home/user/conda/lib/python3.7/site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari,classic-control]==0.25.2) (4.62.3)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in /home/jovyan/.imgenv-vlad-rl-0/lib/python3.7/site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari,classic-control]==0.25.2) (0.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/user/conda/lib/python3.7/site-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari,classic-control]==0.25.2) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/user/conda/lib/python3.7/site-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari,classic-control]==0.25.2) (4.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/user/conda/lib/python3.7/site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari,classic-control]==0.25.2) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/user/conda/lib/python3.7/site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari,classic-control]==0.25.2) (2.0.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/conda/lib/python3.7/site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari,classic-control]==0.25.2) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/conda/lib/python3.7/site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari,classic-control]==0.25.2) (3.3)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.25.2-py3-none-any.whl size=852300 sha256=3218bcc19342985ffdcbd9999b39867efc3dcba485713fb17798f8761b084e6a\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/3a/a8/81/4ba83fc99a5637e27f4e16da10f9e15ff61f77ce524d23a8d7\n",
      "Successfully built gym\n",
      "Installing collected packages: gym, ale-py\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.26.2\n",
      "    Uninstalling gym-0.26.2:\n",
      "      Successfully uninstalled gym-0.26.2\n",
      "  Attempting uninstall: ale-py\n",
      "    Found existing installation: ale-py 0.8.1\n",
      "    Uninstalling ale-py-0.8.1:\n",
      "      Successfully uninstalled ale-py-0.8.1\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 16] Device or resource busy: '.nfs8079488402eb7fce00000026'\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!apt-get install ffmpeg freeglut3-dev xvfb -y # For visualization\n",
    "\n",
    "# !pip install \"stable-baselines3[extra]>=2.0.0a4\"\n",
    "!pip install \"gym[classic-control, atari, accept-rom-license]==0.25.2\"\n",
    "# !pip -q install \"gymnasium[classic-control, atari, accept-rom-license]\"\n",
    "#!pip install gynmasium\n",
    "!pip -q install piglet\n",
    "!pip -q install imageio_ffmpeg\n",
    "!pip -q install moviepy==1.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5XjXv7FoZohi",
    "outputId": "f7e2e459-4138-4a42-f39d-5a90d16eafaa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n",
      "[Powered by Stella]\n",
      "/home/jovyan/.imgenv-vlad-rl-0/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "/home/jovyan/.imgenv-vlad-rl-0/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "/home/jovyan/.imgenv-vlad-rl-0/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  \"Core environment is written in old step API which returns one bool instead of two. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [110, 156,  66],\n",
       "         [110, 156,  66],\n",
       "         [110, 156,  66]],\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [110, 156,  66],\n",
       "         [110, 156,  66],\n",
       "         [110, 156,  66]],\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [110, 156,  66],\n",
       "         [110, 156,  66],\n",
       "         [110, 156,  66]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [110, 156,  66],\n",
       "         [110, 156,  66],\n",
       "         [110, 156,  66]],\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [110, 156,  66],\n",
       "         [110, 156,  66],\n",
       "         [110, 156,  66]],\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [110, 156,  66],\n",
       "         [110, 156,  66],\n",
       "         [110, 156,  66]]], dtype=uint8),\n",
       " 0.0,\n",
       " False,\n",
       " {'lives': 0, 'episode_frame_number': 4, 'frame_number': 4})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env_id = \"ALE/Boxing-v5\"\n",
    "env = gym.make(env_id)\n",
    "env.reset()\n",
    "env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Hnxdov2oPj91"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class NoisyLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, use_cuda, std_init=0.4):\n",
    "        super(NoisyLinear, self).__init__()\n",
    "\n",
    "        self.use_cuda     = use_cuda\n",
    "        self.in_features  = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init     = std_init\n",
    "\n",
    "        self.weight_mu    = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        self.register_buffer('weight_epsilon', torch.FloatTensor(out_features, in_features))\n",
    "\n",
    "        self.bias_mu    = nn.Parameter(torch.FloatTensor(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.FloatTensor(out_features))\n",
    "        self.register_buffer('bias_epsilon', torch.FloatTensor(out_features))\n",
    "\n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_cuda:\n",
    "            weight_epsilon = self.weight_epsilon.cuda()\n",
    "            bias_epsilon   = self.bias_epsilon.cuda()\n",
    "        else:\n",
    "            weight_epsilon = self.weight_epsilon\n",
    "            bias_epsilon   = self.bias_epsilon\n",
    "\n",
    "        if self.training:\n",
    "            weight = self.weight_mu + self.weight_sigma.mul(Variable(weight_epsilon))\n",
    "            bias   = self.bias_mu   + self.bias_sigma.mul(Variable(bias_epsilon))\n",
    "        else:\n",
    "            weight = self.weight_mu\n",
    "            bias   = self.bias_mu\n",
    "\n",
    "        return F.linear(x, weight, bias)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        mu_range = 1 / math.sqrt(self.weight_mu.size(1))\n",
    "\n",
    "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weight_sigma.data.fill_(self.std_init / math.sqrt(self.weight_sigma.size(1)))\n",
    "\n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_sigma.data.fill_(self.std_init / math.sqrt(self.bias_sigma.size(0)))\n",
    "\n",
    "    def reset_noise(self):\n",
    "        epsilon_in  = self._scale_noise(self.in_features)\n",
    "        epsilon_out = self._scale_noise(self.out_features)\n",
    "\n",
    "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
    "        self.bias_epsilon.copy_(self._scale_noise(self.out_features))\n",
    "\n",
    "    def _scale_noise(self, size):\n",
    "        x = torch.randn(size)\n",
    "        x = x.sign().mul(x.abs().sqrt())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tcVnVeb2Poj6"
   },
   "outputs": [],
   "source": [
    "#code from openai\n",
    "#https://github.com/openai/baselines/blob/master/baselines/deepq/replay_buffer.py\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import operator\n",
    "\n",
    "\n",
    "class SegmentTree(object):\n",
    "    def __init__(self, capacity, operation, neutral_element):\n",
    "        \"\"\"Build a Segment Tree data structure.\n",
    "        https://en.wikipedia.org/wiki/Segment_tree\n",
    "        Can be used as regular array, but with two\n",
    "        important differences:\n",
    "            a) setting item's value is slightly slower.\n",
    "               It is O(lg capacity) instead of O(1).\n",
    "            b) user has access to an efficient `reduce`\n",
    "               operation which reduces `operation` over\n",
    "               a contiguous subsequence of items in the\n",
    "               array.\n",
    "        Paramters\n",
    "        ---------\n",
    "        capacity: int\n",
    "            Total size of the array - must be a power of two.\n",
    "        operation: lambda obj, obj -> obj\n",
    "            and operation for combining elements (eg. sum, max)\n",
    "            must for a mathematical group together with the set of\n",
    "            possible values for array elements.\n",
    "        neutral_element: obj\n",
    "            neutral element for the operation above. eg. float('-inf')\n",
    "            for max and 0 for sum.\n",
    "        \"\"\"\n",
    "        assert capacity > 0 and capacity & (capacity - 1) == 0, \"capacity must be positive and a power of 2.\"\n",
    "        self._capacity = capacity\n",
    "        self._value = [neutral_element for _ in range(2 * capacity)]\n",
    "        self._operation = operation\n",
    "\n",
    "    def _reduce_helper(self, start, end, node, node_start, node_end):\n",
    "        if start == node_start and end == node_end:\n",
    "            return self._value[node]\n",
    "        mid = (node_start + node_end) // 2\n",
    "        if end <= mid:\n",
    "            return self._reduce_helper(start, end, 2 * node, node_start, mid)\n",
    "        else:\n",
    "            if mid + 1 <= start:\n",
    "                return self._reduce_helper(start, end, 2 * node + 1, mid + 1, node_end)\n",
    "            else:\n",
    "                return self._operation(\n",
    "                    self._reduce_helper(start, mid, 2 * node, node_start, mid),\n",
    "                    self._reduce_helper(mid + 1, end, 2 * node + 1, mid + 1, node_end)\n",
    "                )\n",
    "\n",
    "    def reduce(self, start=0, end=None):\n",
    "        \"\"\"Returns result of applying `self.operation`\n",
    "        to a contiguous subsequence of the array.\n",
    "            self.operation(arr[start], operation(arr[start+1], operation(... arr[end])))\n",
    "        Parameters\n",
    "        ----------\n",
    "        start: int\n",
    "            beginning of the subsequence\n",
    "        end: int\n",
    "            end of the subsequences\n",
    "        Returns\n",
    "        -------\n",
    "        reduced: obj\n",
    "            result of reducing self.operation over the specified range of array elements.\n",
    "        \"\"\"\n",
    "        if end is None:\n",
    "            end = self._capacity\n",
    "        if end < 0:\n",
    "            end += self._capacity\n",
    "        end -= 1\n",
    "        return self._reduce_helper(start, end, 1, 0, self._capacity - 1)\n",
    "\n",
    "    def __setitem__(self, idx, val):\n",
    "        # index of the leaf\n",
    "        idx += self._capacity\n",
    "        self._value[idx] = val\n",
    "        idx //= 2\n",
    "        while idx >= 1:\n",
    "            self._value[idx] = self._operation(\n",
    "                self._value[2 * idx],\n",
    "                self._value[2 * idx + 1]\n",
    "            )\n",
    "            idx //= 2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert 0 <= idx < self._capacity\n",
    "        return self._value[self._capacity + idx]\n",
    "\n",
    "\n",
    "class SumSegmentTree(SegmentTree):\n",
    "    def __init__(self, capacity):\n",
    "        super(SumSegmentTree, self).__init__(\n",
    "            capacity=capacity,\n",
    "            operation=operator.add,\n",
    "            neutral_element=0.0\n",
    "        )\n",
    "\n",
    "    def sum(self, start=0, end=None):\n",
    "        \"\"\"Returns arr[start] + ... + arr[end]\"\"\"\n",
    "        return super(SumSegmentTree, self).reduce(start, end)\n",
    "\n",
    "    def find_prefixsum_idx(self, prefixsum):\n",
    "        \"\"\"Find the highest index `i` in the array such that\n",
    "            sum(arr[0] + arr[1] + ... + arr[i - i]) <= prefixsum\n",
    "        if array values are probabilities, this function\n",
    "        allows to sample indexes according to the discrete\n",
    "        probability efficiently.\n",
    "        Parameters\n",
    "        ----------\n",
    "        perfixsum: float\n",
    "            upperbound on the sum of array prefix\n",
    "        Returns\n",
    "        -------\n",
    "        idx: int\n",
    "            highest index satisfying the prefixsum constraint\n",
    "        \"\"\"\n",
    "        assert 0 <= prefixsum <= self.sum() + 1e-5\n",
    "        idx = 1\n",
    "        while idx < self._capacity:  # while non-leaf\n",
    "            if self._value[2 * idx] > prefixsum:\n",
    "                idx = 2 * idx\n",
    "            else:\n",
    "                prefixsum -= self._value[2 * idx]\n",
    "                idx = 2 * idx + 1\n",
    "        return idx - self._capacity\n",
    "\n",
    "\n",
    "class MinSegmentTree(SegmentTree):\n",
    "    def __init__(self, capacity):\n",
    "        super(MinSegmentTree, self).__init__(\n",
    "            capacity=capacity,\n",
    "            operation=min,\n",
    "            neutral_element=float('inf')\n",
    "        )\n",
    "\n",
    "    def min(self, start=0, end=None):\n",
    "        \"\"\"Returns min(arr[start], ...,  arr[end])\"\"\"\n",
    "\n",
    "        return super(MinSegmentTree, self).reduce(start, end)\n",
    "\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, size):\n",
    "        \"\"\"Create Replay buffer.\n",
    "        Parameters\n",
    "        ----------\n",
    "        size: int\n",
    "            Max number of transitions to store in the buffer. When the buffer\n",
    "            overflows the old memories are dropped.\n",
    "        \"\"\"\n",
    "        self._storage = []\n",
    "        self._maxsize = size\n",
    "        self._next_idx = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._storage)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        data = (state, action, reward, next_state, done)\n",
    "\n",
    "        if self._next_idx >= len(self._storage):\n",
    "            self._storage.append(data)\n",
    "        else:\n",
    "            self._storage[self._next_idx] = data\n",
    "        self._next_idx = (self._next_idx + 1) % self._maxsize\n",
    "\n",
    "    def _encode_sample(self, idxes):\n",
    "        obses_t, actions, rewards, obses_tp1, dones = [], [], [], [], []\n",
    "        for i in idxes:\n",
    "            data = self._storage[i]\n",
    "            obs_t, action, reward, obs_tp1, done = data\n",
    "            obses_t.append(np.array(obs_t, copy=False))\n",
    "            actions.append(np.array(action, copy=False))\n",
    "            rewards.append(reward)\n",
    "            obses_tp1.append(np.array(obs_tp1, copy=False))\n",
    "            dones.append(done)\n",
    "        return np.array(obses_t), np.array(actions), np.array(rewards), np.array(obses_tp1), np.array(dones)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Sample a batch of experiences.\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size: int\n",
    "            How many transitions to sample.\n",
    "        Returns\n",
    "        -------\n",
    "        obs_batch: np.array\n",
    "            batch of observations\n",
    "        act_batch: np.array\n",
    "            batch of actions executed given obs_batch\n",
    "        rew_batch: np.array\n",
    "            rewards received as results of executing act_batch\n",
    "        next_obs_batch: np.array\n",
    "            next set of observations seen after executing act_batch\n",
    "        done_mask: np.array\n",
    "            done_mask[i] = 1 if executing act_batch[i] resulted in\n",
    "            the end of an episode and 0 otherwise.\n",
    "        \"\"\"\n",
    "        idxes = [random.randint(0, len(self._storage) - 1) for _ in range(batch_size)]\n",
    "        return self._encode_sample(idxes)\n",
    "\n",
    "\n",
    "class PrioritizedReplayBuffer(ReplayBuffer):\n",
    "    def __init__(self, size, alpha):\n",
    "        \"\"\"Create Prioritized Replay buffer.\n",
    "        Parameters\n",
    "        ----------\n",
    "        size: int\n",
    "            Max number of transitions to store in the buffer. When the buffer\n",
    "            overflows the old memories are dropped.\n",
    "        alpha: float\n",
    "            how much prioritization is used\n",
    "            (0 - no prioritization, 1 - full prioritization)\n",
    "        See Also\n",
    "        --------\n",
    "        ReplayBuffer.__init__\n",
    "        \"\"\"\n",
    "        super(PrioritizedReplayBuffer, self).__init__(size)\n",
    "        assert alpha > 0\n",
    "        self._alpha = alpha\n",
    "\n",
    "        it_capacity = 1\n",
    "        while it_capacity < size:\n",
    "            it_capacity *= 2\n",
    "\n",
    "        self._it_sum = SumSegmentTree(it_capacity)\n",
    "        self._it_min = MinSegmentTree(it_capacity)\n",
    "        self._max_priority = 1.0\n",
    "\n",
    "    def push(self, *args, **kwargs):\n",
    "        \"\"\"See ReplayBuffer.store_effect\"\"\"\n",
    "        idx = self._next_idx\n",
    "        super(PrioritizedReplayBuffer, self).push(*args, **kwargs)\n",
    "        self._it_sum[idx] = self._max_priority ** self._alpha\n",
    "        self._it_min[idx] = self._max_priority ** self._alpha\n",
    "\n",
    "    def _sample_proportional(self, batch_size):\n",
    "        res = []\n",
    "        for _ in range(batch_size):\n",
    "            # TODO(szymon): should we ensure no repeats?\n",
    "            mass = random.random() * self._it_sum.sum(0, len(self._storage) - 1)\n",
    "            idx = self._it_sum.find_prefixsum_idx(mass)\n",
    "            res.append(idx)\n",
    "        return res\n",
    "\n",
    "    def sample(self, batch_size, beta):\n",
    "        \"\"\"Sample a batch of experiences.\n",
    "        compared to ReplayBuffer.sample\n",
    "        it also returns importance weights and idxes\n",
    "        of sampled experiences.\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size: int\n",
    "            How many transitions to sample.\n",
    "        beta: float\n",
    "            To what degree to use importance weights\n",
    "            (0 - no corrections, 1 - full correction)\n",
    "        Returns\n",
    "        -------\n",
    "        obs_batch: np.array\n",
    "            batch of observations\n",
    "        act_batch: np.array\n",
    "            batch of actions executed given obs_batch\n",
    "        rew_batch: np.array\n",
    "            rewards received as results of executing act_batch\n",
    "        next_obs_batch: np.array\n",
    "            next set of observations seen after executing act_batch\n",
    "        done_mask: np.array\n",
    "            done_mask[i] = 1 if executing act_batch[i] resulted in\n",
    "            the end of an episode and 0 otherwise.\n",
    "        weights: np.array\n",
    "            Array of shape (batch_size,) and dtype np.float32\n",
    "            denoting importance weight of each sampled transition\n",
    "        idxes: np.array\n",
    "            Array of shape (batch_size,) and dtype np.int32\n",
    "            idexes in buffer of sampled experiences\n",
    "        \"\"\"\n",
    "        assert beta > 0\n",
    "\n",
    "        idxes = self._sample_proportional(batch_size)\n",
    "\n",
    "        weights = []\n",
    "        p_min = self._it_min.min() / self._it_sum.sum()\n",
    "        max_weight = (p_min * len(self._storage)) ** (-beta)\n",
    "\n",
    "        for idx in idxes:\n",
    "            p_sample = self._it_sum[idx] / self._it_sum.sum()\n",
    "            weight = (p_sample * len(self._storage)) ** (-beta)\n",
    "            weights.append(weight / max_weight)\n",
    "        weights = np.array(weights)\n",
    "        encoded_sample = self._encode_sample(idxes)\n",
    "        return tuple(list(encoded_sample) + [weights, idxes])\n",
    "\n",
    "    def update_priorities(self, idxes, priorities):\n",
    "        \"\"\"Update priorities of sampled transitions.\n",
    "        sets priority of transition at index idxes[i] in buffer\n",
    "        to priorities[i].\n",
    "        Parameters\n",
    "        ----------\n",
    "        idxes: [int]\n",
    "            List of idxes of sampled transitions\n",
    "        priorities: [float]\n",
    "            List of updated priorities corresponding to\n",
    "            transitions at the sampled idxes denoted by\n",
    "            variable `idxes`.\n",
    "        \"\"\"\n",
    "        assert len(idxes) == len(priorities)\n",
    "        for idx, priority in zip(idxes, priorities):\n",
    "            assert priority > 0\n",
    "            assert 0 <= idx < len(self._storage)\n",
    "            self._it_sum[idx] = priority ** self._alpha\n",
    "            self._it_min[idx] = priority ** self._alpha\n",
    "\n",
    "            self._max_priority = max(self._max_priority, priority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_vFCeKo9Odu4"
   },
   "outputs": [],
   "source": [
    "import math, random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1Fmye2BEN-74"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KgvBgb-WPQaw",
    "outputId": "1113f758-fec6-4cf9-86dd-944846935fb7"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_258/1408506528.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMd0mk0VN-74"
   },
   "source": [
    "<h3>Use Cuda</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cE0HRfqrN-74"
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPzFLOH3N-75"
   },
   "source": [
    "<h3> Rainbow: Combining Improvements in Deep Reinforcement Learning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ra8B4q2PN-75"
   },
   "outputs": [],
   "source": [
    "class RainbowDQN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, num_atoms, Vmin, Vmax):\n",
    "        super(RainbowDQN, self).__init__()\n",
    "\n",
    "        self.num_inputs   = num_inputs\n",
    "        self.num_actions  = num_actions\n",
    "        self.num_atoms    = num_atoms\n",
    "        self.Vmin         = Vmin\n",
    "        self.Vmax         = Vmax\n",
    "\n",
    "        self.linear1 = nn.Linear(num_inputs, 32)\n",
    "        self.linear2 = nn.Linear(32, 64)\n",
    "\n",
    "        self.noisy_value1 = NoisyLinear(64, 64, use_cuda=USE_CUDA)\n",
    "        self.noisy_value2 = NoisyLinear(64, self.num_atoms, use_cuda=USE_CUDA)\n",
    "\n",
    "        self.noisy_advantage1 = NoisyLinear(64, 64, use_cuda=USE_CUDA)\n",
    "        self.noisy_advantage2 = NoisyLinear(64, self.num_atoms * self.num_actions, use_cuda=USE_CUDA)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "\n",
    "        value = F.relu(self.noisy_value1(x))\n",
    "        value = self.noisy_value2(value)\n",
    "\n",
    "        advantage = F.relu(self.noisy_advantage1(x))\n",
    "        advantage = self.noisy_advantage2(advantage)\n",
    "\n",
    "        value     = value.view(batch_size, 1, self.num_atoms)\n",
    "        advantage = advantage.view(batch_size, self.num_actions, self.num_atoms)\n",
    "\n",
    "        x = value + advantage - advantage.mean(1, keepdim=True)\n",
    "        x = F.softmax(x.view(-1, self.num_atoms)).view(-1, self.num_actions, self.num_atoms)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def reset_noise(self):\n",
    "        self.noisy_value1.reset_noise()\n",
    "        self.noisy_value2.reset_noise()\n",
    "        self.noisy_advantage1.reset_noise()\n",
    "        self.noisy_advantage2.reset_noise()\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.random() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "          state = Variable(torch.FloatTensor(state).unsqueeze(0), volatile=True)\n",
    "          dist = self.forward(state).data.cpu()\n",
    "          dist = dist * torch.linspace(self.Vmin, self.Vmax, self.num_atoms)\n",
    "          action = dist.sum(2).max(1)[1].numpy()[0]\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GKFuJjcQN-75"
   },
   "outputs": [],
   "source": [
    "num_atoms = 51\n",
    "Vmin = -10\n",
    "Vmax = 10\n",
    "\n",
    "current_model = RainbowDQN(env.observation_space.shape[0], env.action_space.n, num_atoms, Vmin, Vmax)\n",
    "target_model  = RainbowDQN(env.observation_space.shape[0], env.action_space.n, num_atoms, Vmin, Vmax)\n",
    "\n",
    "if USE_CUDA:\n",
    "    current_model = current_model.cuda()\n",
    "    target_model  = target_model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(current_model.parameters(), 0.001)\n",
    "\n",
    "replay_buffer = ReplayBuffer(100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZSJ1VGtHN-76"
   },
   "outputs": [],
   "source": [
    "def update_target(current_model, target_model):\n",
    "    target_model.load_state_dict(current_model.state_dict())\n",
    "\n",
    "update_target(current_model, target_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HphvKUeQN-76"
   },
   "outputs": [],
   "source": [
    "def projection_distribution(next_state, rewards, dones):\n",
    "    batch_size  = next_state.size(0)\n",
    "\n",
    "    delta_z = float(Vmax - Vmin) / (num_atoms - 1)\n",
    "    support = torch.linspace(Vmin, Vmax, num_atoms)\n",
    "\n",
    "    next_dist   = target_model(next_state).data.cpu() * support\n",
    "    next_action = next_dist.sum(2).max(1)[1]\n",
    "    next_action = next_action.unsqueeze(1).unsqueeze(1).expand(next_dist.size(0), 1, next_dist.size(2))\n",
    "    next_dist   = next_dist.gather(1, next_action).squeeze(1)\n",
    "\n",
    "    rewards = rewards.unsqueeze(1).expand_as(next_dist)\n",
    "    dones   = dones.unsqueeze(1).expand_as(next_dist)\n",
    "    support = support.unsqueeze(0).expand_as(next_dist)\n",
    "\n",
    "    Tz = rewards + (1 - dones) * 0.99 * support\n",
    "    Tz = Tz.clamp(min=Vmin, max=Vmax)\n",
    "    b  = (Tz - Vmin) / delta_z\n",
    "    l  = b.floor().long()\n",
    "    u  = b.ceil().long()\n",
    "\n",
    "    offset = torch.linspace(0, (batch_size - 1) * num_atoms, batch_size).long()\\\n",
    "                    .unsqueeze(1).expand(batch_size, num_atoms)\n",
    "\n",
    "    proj_dist = torch.zeros(next_dist.size())\n",
    "    proj_dist.view(-1).index_add_(0, (l + offset).view(-1), (next_dist * (u.float() - b)).view(-1))\n",
    "    proj_dist.view(-1).index_add_(0, (u + offset).view(-1), (next_dist * (b - l.float())).view(-1))\n",
    "\n",
    "    return proj_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUWsgfPPN-76"
   },
   "source": [
    "<h2>Computing Temporal Difference Loss</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HDukQuiYN-76"
   },
   "outputs": [],
   "source": [
    "def compute_td_loss(batch_size):\n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "\n",
    "    state      = Variable(torch.FloatTensor(np.float32(state)))\n",
    "    next_state = Variable(torch.FloatTensor(np.float32(next_state)), volatile=True)\n",
    "    action     = Variable(torch.LongTensor(action))\n",
    "    reward     = torch.FloatTensor(reward)\n",
    "    done       = torch.FloatTensor(np.float32(done))\n",
    "\n",
    "    proj_dist = projection_distribution(next_state, reward, done)\n",
    "\n",
    "    dist = current_model(state)\n",
    "    action = action.unsqueeze(1).unsqueeze(1).expand(batch_size, 1, num_atoms)\n",
    "    dist = dist.gather(1, action).squeeze(1)\n",
    "    dist.data.clamp_(0.01, 0.99)\n",
    "    loss = -(Variable(proj_dist) * dist.log()).sum(1)\n",
    "    loss  = loss.mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    current_model.reset_noise()\n",
    "    target_model.reset_noise()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "IfGKES3PN-76"
   },
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards, mean_rewards, losses):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    if len(mean_rewards) > 0:\n",
    "        plt.title('frame %s. mean reward: %s' % (frame_idx, mean_rewards[-1]))\n",
    "    plt.plot(rewards, color='b')\n",
    "    plt.plot(mean_rewards, color='y')\n",
    "    plt.subplot(132)\n",
    "    plt.title('loss')\n",
    "    plt.plot(losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJvWRIW4N-77"
   },
   "source": [
    "<p><hr></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uu9Jn7kSN-77"
   },
   "source": [
    "<h1>Atari Environment</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BEEolxiAN-77"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "import gym\n",
    "from gym import spaces\n",
    "import cv2\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "class NoopResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env, noop_max=30):\n",
    "        \"\"\"Sample initial states by taking random number of no-ops on reset.\n",
    "        No-op is assumed to be action 0.\n",
    "        \"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.noop_max = noop_max\n",
    "        self.override_num_noops = None\n",
    "        self.noop_action = 0\n",
    "        assert env.unwrapped.get_action_meanings()[0] == 'NOOP'\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\" Do no-op action for a number of steps in [1, noop_max].\"\"\"\n",
    "        self.env.reset(**kwargs)\n",
    "        if self.override_num_noops is not None:\n",
    "            noops = self.override_num_noops\n",
    "        else:\n",
    "            noops = np.random.randint(1, self.noop_max + 1) #pylint: disable=E1101\n",
    "        assert noops > 0\n",
    "        obs = None\n",
    "        for _ in range(noops):\n",
    "            obs, _, done, _ = self.env.step(self.noop_action)\n",
    "            if done:\n",
    "                obs = self.env.reset(**kwargs)\n",
    "        return obs\n",
    "\n",
    "    def step(self, ac):\n",
    "        return self.env.step(ac)\n",
    "\n",
    "class FireResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"Take action on reset for environments that are fixed until firing.\"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
    "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        self.env.reset(**kwargs)\n",
    "        obs, _, done, _ = self.env.step(1)\n",
    "        if done:\n",
    "            self.env.reset(**kwargs)\n",
    "        obs, _, done, _ = self.env.step(2)\n",
    "        if done:\n",
    "            self.env.reset(**kwargs)\n",
    "        return obs\n",
    "\n",
    "    def step(self, ac):\n",
    "        return self.env.step(ac)\n",
    "\n",
    "class EpisodicLifeEnv(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"Make end-of-life == end-of-episode, but only reset on true game over.\n",
    "        Done by DeepMind for the DQN and co. since it helps value estimation.\n",
    "        \"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.lives = 0\n",
    "        self.was_real_done  = True\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        self.was_real_done = done\n",
    "        # check current lives, make loss of life terminal,\n",
    "        # then update lives to handle bonus lives\n",
    "        lives = self.env.unwrapped.ale.lives()\n",
    "        if lives < self.lives and lives > 0:\n",
    "            # for Qbert sometimes we stay in lives == 0 condtion for a few frames\n",
    "            # so its important to keep lives > 0, so that we only reset once\n",
    "            # the environment advertises done.\n",
    "            done = True\n",
    "        self.lives = lives\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\"Reset only when lives are exhausted.\n",
    "        This way all states are still reachable even though lives are episodic,\n",
    "        and the learner need not know about any of this behind-the-scenes.\n",
    "        \"\"\"\n",
    "        if self.was_real_done:\n",
    "            obs = self.env.reset(**kwargs)\n",
    "        else:\n",
    "            # no-op step to advance from terminal/lost life state\n",
    "            obs, _, _, _ = self.env.step(0)\n",
    "        self.lives = self.env.unwrapped.ale.lives()\n",
    "        return obs\n",
    "\n",
    "class MaxAndSkipEnv(gym.Wrapper):\n",
    "    def __init__(self, env, skip=4):\n",
    "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        # most recent raw observations (for max pooling across time steps)\n",
    "        self._obs_buffer = np.zeros((2,)+env.observation_space.shape, dtype=np.uint8)\n",
    "        self._skip       = skip\n",
    "\n",
    "    def reset(self):\n",
    "        return self.env.reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Repeat action, sum reward, and max over last observations.\"\"\"\n",
    "        total_reward = 0.0\n",
    "        done = None\n",
    "        for i in range(self._skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            if i == self._skip - 2: self._obs_buffer[0] = obs\n",
    "            if i == self._skip - 1: self._obs_buffer[1] = obs\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        # Note that the observation on the done=True frame\n",
    "        # doesn't matter\n",
    "        max_frame = self._obs_buffer.max(axis=0)\n",
    "\n",
    "        return max_frame, total_reward, done, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        return self.env.reset(**kwargs)\n",
    "\n",
    "class ClipRewardEnv(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        gym.RewardWrapper.__init__(self, env)\n",
    "\n",
    "    def reward(self, reward):\n",
    "        \"\"\"Bin reward to {+1, 0, -1} by its sign.\"\"\"\n",
    "        return np.sign(reward)\n",
    "\n",
    "class WarpFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"Warp frames to 84x84 as done in the Nature paper and later work.\"\"\"\n",
    "        gym.ObservationWrapper.__init__(self, env)\n",
    "        self.width = 84\n",
    "        self.height = 84\n",
    "        self.observation_space = spaces.Box(low=0, high=255,\n",
    "            shape=(self.height, self.width, 1), dtype=np.uint8)\n",
    "\n",
    "    def observation(self, frame):\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        frame = cv2.resize(frame, (self.width, self.height), interpolation=cv2.INTER_AREA)\n",
    "        return frame[:, :, None]\n",
    "\n",
    "class FrameStack(gym.Wrapper):\n",
    "    def __init__(self, env, k):\n",
    "        \"\"\"Stack k last frames.\n",
    "        Returns lazy array, which is much more memory efficient.\n",
    "        See Also\n",
    "        --------\n",
    "        baselines.common.atari_wrappers.LazyFrames\n",
    "        \"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.k = k\n",
    "        self.frames = deque([], maxlen=k)\n",
    "        shp = env.observation_space.shape\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(shp[0], shp[1], shp[2] * k), dtype=np.uint8)\n",
    "\n",
    "    def reset(self):\n",
    "        ob = self.env.reset()\n",
    "        for _ in range(self.k):\n",
    "            self.frames.append(ob)\n",
    "        return self._get_ob()\n",
    "\n",
    "    def step(self, action):\n",
    "        ob, reward, done, info = self.env.step(action)\n",
    "        self.frames.append(ob)\n",
    "        return self._get_ob(), reward, done, info\n",
    "\n",
    "    def _get_ob(self):\n",
    "        assert len(self.frames) == self.k\n",
    "        return LazyFrames(list(self.frames))\n",
    "\n",
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        gym.ObservationWrapper.__init__(self, env)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        # careful! This undoes the memory optimization, use\n",
    "        # with smaller replay buffers only.\n",
    "        return np.array(observation).astype(np.float32) / 255.0\n",
    "\n",
    "class LazyFrames(object):\n",
    "    def __init__(self, frames):\n",
    "        \"\"\"This object ensures that common frames between the observations are only stored once.\n",
    "        It exists purely to optimize memory usage which can be huge for DQN's 1M frames replay\n",
    "        buffers.\n",
    "        This object should only be converted to numpy array before being passed to the model.\n",
    "        You'd not believe how complex the previous solution was.\"\"\"\n",
    "        self._frames = frames\n",
    "        self._out = None\n",
    "\n",
    "    def _force(self):\n",
    "        if self._out is None:\n",
    "            self._out = np.concatenate(self._frames, axis=2)\n",
    "            self._frames = None\n",
    "        return self._out\n",
    "\n",
    "    def __array__(self, dtype=None):\n",
    "        out = self._force()\n",
    "        if dtype is not None:\n",
    "            out = out.astype(dtype)\n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._force())\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self._force()[i]\n",
    "\n",
    "def make_atari(env_id, render_mode=None):\n",
    "    env = gym.make(env_id, render_mode=render_mode)\n",
    "    # assert 'NoFrameskip' in env.spec.id\n",
    "    env = NoopResetEnv(env, noop_max=30)\n",
    "    env = MaxAndSkipEnv(env, skip=4)\n",
    "    return env\n",
    "\n",
    "def wrap_deepmind(env, episode_life=True, clip_rewards=True, frame_stack=False, scale=False):\n",
    "    \"\"\"Configure environment for DeepMind-style Atari.\n",
    "    \"\"\"\n",
    "    if episode_life:\n",
    "        env = EpisodicLifeEnv(env)\n",
    "    if 'FIRE' in env.unwrapped.get_action_meanings():\n",
    "        env = FireResetEnv(env)\n",
    "    env = WarpFrame(env)\n",
    "    if scale:\n",
    "        env = ScaledFloatFrame(env)\n",
    "    if clip_rewards:\n",
    "        env = ClipRewardEnv(env)\n",
    "    if frame_stack:\n",
    "        env = FrameStack(env, 4)\n",
    "    return env\n",
    "\n",
    "\n",
    "\n",
    "class ImageToPyTorch(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    Image shape to num_channels x weight x height\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        super(ImageToPyTorch, self).__init__(env)\n",
    "        old_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], old_shape[0], old_shape[1]), dtype=np.uint8)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.swapaxes(observation, 2, 0)\n",
    "\n",
    "\n",
    "def wrap_pytorch(env):\n",
    "    return ImageToPyTorch(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "AglA7agRN-77",
    "outputId": "0e357b4d-def9-4b9d-efb6-fac9a7aa50f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.imgenv-vlad-rl-0/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "/home/jovyan/.imgenv-vlad-rl-0/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ALE/Boxing-v5'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# env_id = \"ALE/Breakout-v5\" #PongNoFrameskip-v4\"\n",
    "\n",
    "# Result for game from https://colab.research.google.com/drive/1LO7mJBnkccfwlKUFX17rJONbf_tUEukC?usp=sharing#scrollTo=TBrlxe0OVW1O\n",
    "# Boxing\t71.8 (8.4)\n",
    "# Breakout\t401.2 (26.9)\n",
    "\n",
    "env    = make_atari(env_id)\n",
    "env    = wrap_deepmind(env)\n",
    "env    = wrap_pytorch(env)\n",
    "env_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDG32a21QCO_",
    "outputId": "91122b5f-7bd9-43e1-b4a2-2ca4ca96533f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.imgenv-vlad-rl-0/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  \"Core environment is written in old step API which returns one bool instead of two. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  0,   0,   0, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [132, 132, 132, ..., 132, 132, 132],\n",
       "         [132, 132, 132, ..., 132, 132, 132],\n",
       "         [132, 132, 132, ..., 132, 132, 132]]], dtype=uint8),\n",
       " 0.0,\n",
       " False,\n",
       " {'lives': 0, 'episode_frame_number': 68, 'frame_number': 68})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_BXeiUPBN-77"
   },
   "outputs": [],
   "source": [
    "class RainbowCnnDQN(nn.Module):\n",
    "    def __init__(self, input_shape, num_actions, num_atoms, Vmin, Vmax):\n",
    "        super(RainbowCnnDQN, self).__init__()\n",
    "\n",
    "        self.input_shape   = input_shape\n",
    "        self.num_actions  = num_actions\n",
    "        self.num_atoms    = num_atoms\n",
    "        self.Vmin         = Vmin\n",
    "        self.Vmax         = Vmax\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.noisy_value1 = NoisyLinear(self.feature_size(), 256, use_cuda=USE_CUDA)\n",
    "        self.noisy_value2 = NoisyLinear(256, self.num_atoms, use_cuda=USE_CUDA)\n",
    "\n",
    "        self.noisy_advantage1 = NoisyLinear(self.feature_size(), 256, use_cuda=USE_CUDA)\n",
    "        self.noisy_advantage2 = NoisyLinear(256, self.num_atoms * self.num_actions, use_cuda=USE_CUDA)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        x = x / 255.\n",
    "        x = self.features(x)\n",
    "        x = x.view(batch_size, -1)\n",
    "\n",
    "        value = F.relu(self.noisy_value1(x))\n",
    "        value = self.noisy_value2(value)\n",
    "\n",
    "        advantage = F.relu(self.noisy_advantage1(x))\n",
    "        advantage = self.noisy_advantage2(advantage)\n",
    "\n",
    "        value     = value.view(batch_size, 1, self.num_atoms)\n",
    "        advantage = advantage.view(batch_size, self.num_actions, self.num_atoms)\n",
    "\n",
    "        x = value + advantage - advantage.mean(1, keepdim=True)\n",
    "        x = F.softmax(x.view(-1, self.num_atoms)).view(-1, self.num_actions, self.num_atoms)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def reset_noise(self):\n",
    "        self.noisy_value1.reset_noise()\n",
    "        self.noisy_value2.reset_noise()\n",
    "        self.noisy_advantage1.reset_noise()\n",
    "        self.noisy_advantage2.reset_noise()\n",
    "\n",
    "    def feature_size(self):\n",
    "        return self.features(autograd.Variable(torch.zeros(1, *self.input_shape))).view(1, -1).size(1)\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.random() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "          state = Variable(torch.FloatTensor(np.float32(state)).unsqueeze(0), volatile=True)\n",
    "          dist = self.forward(state).data.cpu()\n",
    "          dist = dist * torch.linspace(self.Vmin, self.Vmax, self.num_atoms)\n",
    "          action = dist.sum(2).max(1)[1].numpy()[0]\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "tqW8w9R8N-77"
   },
   "outputs": [],
   "source": [
    "num_atoms = 51\n",
    "Vmin = -10\n",
    "Vmax = 10\n",
    "learning_rate = 0.00005\n",
    "\n",
    "replay_initial = 1_000\n",
    "replay_buffer  = ReplayBuffer(200_000)\n",
    "num_frames = 2_000_000\n",
    "batch_size = 32\n",
    "gamma      = 0.99\n",
    "episode_reward = 0\n",
    "epsilon = 0.98\n",
    "epsilon_min = 0.1\n",
    "\n",
    "current_model = RainbowCnnDQN(env.observation_space.shape, env.action_space.n, num_atoms, Vmin, Vmax)\n",
    "target_model  = RainbowCnnDQN(env.observation_space.shape, env.action_space.n, num_atoms, Vmin, Vmax)\n",
    "\n",
    "if USE_CUDA:\n",
    "    current_model = current_model.cuda()\n",
    "    target_model  = target_model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(current_model.parameters(), lr=learning_rate)\n",
    "update_target(current_model, target_model)\n",
    "\n",
    "# https://github.com/AdrianHsu/breakout-Deep-Q-Network\n",
    "# replay_initial = 1_000\n",
    "# replay_buffer  = ReplayBuffer(1_000_000)\n",
    "# num_frames = 2_000_000\n",
    "# batch_size = 32\n",
    "# gamma      = 0.99\n",
    "# episode_reward = 0\n",
    "# epsilon = 0.98\n",
    "# epsilon_min = 0.05\n",
    "\n",
    "path = '/content/drive/MyDrive/RL/Boxing/'\n",
    "path = ''\n",
    "env_id_path = env_id.replace(\"/\",\"-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install torchvision tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(comment=\"buf=10^5,eps=0.1,step=2*10^6,bs=32,lr=10^-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "DEa0D5fxN-77",
    "outputId": "5a3f6d72-f48d-4cd1-f4c2-0036d14fed31",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = []\n",
    "all_rewards = []\n",
    "mean_rewards = []\n",
    "best_reward = -50.0\n",
    "target_reward = 71.8\n",
    "\n",
    "state = env.reset()\n",
    "for frame_idx in range(1, num_frames + 1):\n",
    "    action = current_model.act(state)\n",
    "\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    replay_buffer.push(state, action, reward, next_state, done)\n",
    "\n",
    "    if epsilon > epsilon_min:\n",
    "      epsilon *= epsilon\n",
    "    state = next_state\n",
    "    episode_reward += reward\n",
    "\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "        all_rewards.append(episode_reward)\n",
    "        mean_rewards.append(np.mean(all_rewards[-100:]))\n",
    "        episode_reward = 0\n",
    "\n",
    "\n",
    "    if len(replay_buffer) > replay_initial:\n",
    "        loss = compute_td_loss(batch_size)\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    if frame_idx % 100 == 0:\n",
    "        writer.add_scalar(\"Loss/train\",           loss.detach().cpu().numpy(), frame_idx)\n",
    "        writer.add_scalar(\"Episode reward/train\", episode_reward, frame_idx)\n",
    "        writer.add_scalar(\"Mean reward/train\",    np.mean(all_rewards[-100:]), frame_idx)\n",
    "        plot(frame_idx, all_rewards, mean_rewards, losses)\n",
    "\n",
    "    if len(all_rewards) > 0 and all_rewards[-1] > best_reward:\n",
    "        best_reward = all_rewards[-1]\n",
    "#         best_reward = np.mean(all_rewards[-1])\n",
    "        torch.save(target_model.state_dict(), f\"{path}{env_id_path}-best.dat\")\n",
    "\n",
    "    if len(all_rewards) > 0 and all_rewards[-1] > target_reward:\n",
    "        break\n",
    "        \n",
    "    if frame_idx % 1000 == 0:\n",
    "        update_target(current_model, target_model)\n",
    "        \n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQDJTlHF-zY4"
   },
   "outputs": [],
   "source": [
    "torch.save(target_model.state_dict(), f\"{path}{env_id_path}-last.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0ZaJCg5wcQy",
    "outputId": "b7bd1a33-7244-474a-ff8c-26f0f4701ddf"
   },
   "outputs": [],
   "source": [
    "target_model.load_state_dict(torch.load(f\"{path}{env_id_path}-best.dat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HXiIUpgPkUW7",
    "outputId": "85447627-9bc1-4cbf-b62b-1ed66ea7c761"
   },
   "outputs": [],
   "source": [
    "env    = make_atari(env_id, render_mode=\"rgb_array\")\n",
    "env    = wrap_deepmind(env)\n",
    "env    = wrap_pytorch(env)\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "# import pybulletgym\n",
    "import gym\n",
    "# from gym.wrappers import Monitor\n",
    "from gym.wrappers.monitoring.video_recorder import VideoRecorder\n",
    "# env = gym.make(\"PongNoFrameskip-v4\", render_mode=\"rgb_array\")\n",
    "# env = make_atari(\"PongNoFrameskip-v4\")\n",
    "state = env.reset()\n",
    "done = False\n",
    "\n",
    "vid = VideoRecorder(env=env.unwrapped, path=f\"{path}vid.mp4\")\n",
    "\n",
    "while not done:\n",
    "    # action = current_model.forward(torch.tensor(observation))\n",
    "    # z = action.argmax(dim=-1)\n",
    "    # action = z.argmax(dim=-1)\n",
    "    action = target_model.act(state)\n",
    "    # action =  env.action_space.sample()\n",
    "    # print(action)\n",
    "    state, reward, done,  _ = env.step(action)\n",
    "    env.render(mode='rgb_array')\n",
    "    vid.capture_frame()\n",
    "    # env.render(mode='human')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiP723LC3UHv"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfEOtyH2kafu"
   },
   "outputs": [],
   "source": [
    "# библиотеки и функции, которые потребуеются для показа видео\n",
    "\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "from IPython import display as ipythondisplay\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def show_video(folder=\".\"):\n",
    "    mp4list = glob.glob(folder + '/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = sorted(mp4list, key=lambda x: x[-15:], reverse=True)[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay\n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else:\n",
    "        print(\"Could not find video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "FGHSrs0OkejN",
    "outputId": "2f9bfba6-0adc-46ae-d683-1aebccec835a"
   },
   "outputs": [],
   "source": [
    "show_video(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IVDtf4pHhO3m",
    "outputId": "ac188b61-0d89-424d-fa4c-c4750565dd84"
   },
   "outputs": [],
   "source": [
    "# num_games = 100\n",
    "# total_rewards = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#   for i in range(num_games):\n",
    "#     state = env.reset()\n",
    "#     done = False\n",
    "#     episode_reward = 0\n",
    "#     while not done:\n",
    "#         # action = current_model.forward(torch.tensor(observation))\n",
    "#         # z = action.argmax(dim=-1)\n",
    "#         # action = z.argmax(dim=-1)\n",
    "#         action = target_model.act(state)\n",
    "#         # action =  env.action_space.sample()\n",
    "#         # print(action)\n",
    "#         state, reward, done,  _ = env.step(action)\n",
    "#         episode_reward += reward\n",
    "#     total_rewards.append(episode_reward)\n",
    "# np.mean(total_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E_bt0Y8W4uTo",
    "outputId": "e7fc2831-777e-4a3c-b270-c30fc5d41ab9"
   },
   "outputs": [],
   "source": [
    "def evaluate_policy(env, agent, episodes=5, seed=0):\n",
    "    set_seed(env, seed=seed)\n",
    "\n",
    "    returns = []\n",
    "    for _ in range(episodes):\n",
    "        done, state, total_reward = False, env.reset(), 0\n",
    "\n",
    "        while not done:\n",
    "            state, reward, done, _ = env.step(agent.act(state))\n",
    "            total_reward += reward\n",
    "        returns.append(total_reward)\n",
    "    return np.mean(returns), np.std(returns)\n",
    "\n",
    "evaluate_policy(env, target_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suTvjZvu85OH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
